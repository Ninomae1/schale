import requests
from bs4 import BeautifulSoup
import csv
import os
from urllib.parse import urljoin, urlparse

# è¨­å®š
url = "https://bluearchive.wikiru.jp/?ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è¦§"
output_dir = "."
os.makedirs(output_dir, exist_ok=True)

# ãƒšãƒ¼ã‚¸å–å¾—
response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
response.encoding = "utf-8"
soup = BeautifulSoup(response.text, "html.parser")

# ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—
tables = soup.find_all("table", class_="style_table")

# ç”»åƒä¿å­˜é–¢æ•°
def download_image(img_url, save_dir, filename_hint="image"):
    if isinstance(img_url, list):
        img_url = img_url[0]
    parsed = urlparse(img_url)
    ext = os.path.splitext(parsed.path)[1]
    if not ext:
        ext = ".png"
    filename = f"{filename_hint}{ext}"
    filepath = os.path.join(save_dir, filename)

    base, ext = os.path.splitext(filename)
    count = 1
    while os.path.exists(filepath):
        filename = f"{base}_{count}{ext}"
        filepath = os.path.join(save_dir, filename)
        count += 1

    try:
        response = requests.get(img_url, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()
        with open(filepath, "wb") as f:
            f.write(response.content)
        return filename
    except Exception as e:
        print(f"âš  ç”»åƒå–å¾—å¤±æ•—: {img_url} ({e})")
        return "[ç”»åƒå–å¾—å¤±æ•—]"

# ãƒ†ãƒ¼ãƒ–ãƒ«å‡¦ç†
for idx, table in enumerate(tables, start=1):
    rows_raw = table.find_all("tr")
    if not rows_raw:
        continue

    rows = []

    for row_index, tr in enumerate(rows_raw):
        cells = tr.find_all(["th", "td"])
        row_data = []
        image_saved_in_row = False

        # âœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã¯3åˆ—ç›®ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹2ï¼‰
        char_name = None
        if len(cells) > 2:
            char_name = cells[2].get_text(strip=True).replace("/", "_").replace("\\", "_")

        for cell in cells:
            img_tag = cell.find("img")
            if img_tag:
                img_src = img_tag.get("data-src") or img_tag.get("src")
                if isinstance(img_src, list):
                    img_src = img_src[0]
                if img_src and not img_src.startswith("data:"):
                    img_url = urljoin(url, img_src)

                    # âœ… ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«
                    if idx in [35, 36, 37]:
                        row_data.append("[ç”»åƒã‚¹ã‚­ãƒƒãƒ—]")
                        continue

                    if idx == 38:
                        if not image_saved_in_row and char_name:
                            filename = download_image(img_url, output_dir, f"{char_name}_icon")
                            image_saved_in_row = True
                            row_data.append(filename)
                        else:
                            row_data.append("[ç”»åƒã‚¹ã‚­ãƒƒãƒ—]")
                    else:
                        filename = download_image(img_url, output_dir, f"table{idx}_row{row_index}")
                        row_data.append(filename)
                else:
                    row_data.append("[base64ç”»åƒ]")
            else:
                text = cell.get_text(strip=True)
                if "_icon.png" in text:
                    icon_url = f"https://bluearchive.wikiru.jp/?plugin=ref&page=ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è¦§&src={text}"

                    if idx in [35, 36, 37]:
                        row_data.append("[ç”»åƒã‚¹ã‚­ãƒƒãƒ—]")
                        continue

                    if idx == 38:
                        if not image_saved_in_row and char_name:
                            filename = download_image(icon_url, output_dir, f"{char_name}_icon")
                            image_saved_in_row = True
                            row_data.append(filename)
                        else:
                            row_data.append("[ç”»åƒã‚¹ã‚­ãƒƒãƒ—]")
                    else:
                        filename = download_image(icon_url, output_dir, text.replace("_icon.png", "") + "_icon")
                        row_data.append(filename)
                else:
                    row_data.append(text)
        if row_data:
            rows.append(row_data)

    if len(rows) < 2:
        continue

    headers = rows[0]
    data_rows = rows[1:]

    if idx == 38:
        csv_path = os.path.join(output_dir, "all_character.csv")
        with open(csv_path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(headers)
            writer.writerows(data_rows)
        print(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ«[38] ã‚’ä¿å­˜: {csv_path}")
    else:
        print(f"\n--- [ãƒ†ãƒ¼ãƒ–ãƒ« {idx}] å‡ºåŠ›ï¼ˆå…ˆé ­5è¡Œï¼‰ ---")
        print(" | ".join(headers))
        for row in data_rows[:5]:
            print(" | ".join(row))
        print(f"...ï¼ˆå…¨ {len(data_rows)} è¡Œï¼‰\n")

print("ğŸ‰ å®Œäº†ï¼štable38 ã‚­ãƒ£ãƒ©ç”»åƒï¼ˆã‚­ãƒ£ãƒ©å_icon.pngï¼‰ä¿å­˜æ¸ˆã¿ã€ä»–ã‚‚æ­£å¸¸å‡¦ç†ã€‚")
